{"cells":[{"cell_type":"code","source":["from pyspark.sql import functions as F\n","from pyspark.sql.types import *\n","\n","print(\"NYC TAXI Bronze to Silver\")\n","\n","spark.conf.set(\"spark.sql.parquet.enableVectorizedReader\", \"false\")\n","\n","def standardize_schema(df):\n","    if 'Airport_fee' in df.columns:\n","        df = df.withColumnRenamed('Airport_fee', 'airport_fee')\n","    \n","    if 'airport_fee' not in df.columns:\n","        df = df.withColumn('airport_fee', F.lit(None).cast(DoubleType()))\n","    \n","    partition_cols = ['year', 'month', 'day']\n","    for col in partition_cols:\n","        if col in df.columns:\n","            df = df.drop(col)\n","    \n","    standardized = df.select(\n","        F.col('VendorID').cast(IntegerType()).alias('VendorID'),\n","        F.col('tpep_pickup_datetime').alias('tpep_pickup_datetime'),\n","        F.col('tpep_dropoff_datetime').alias('tpep_dropoff_datetime'),\n","        F.col('passenger_count').cast(IntegerType()).alias('passenger_count'),\n","        F.col('trip_distance').cast(DoubleType()).alias('trip_distance'),\n","        F.col('RatecodeID').cast(IntegerType()).alias('RatecodeID'),\n","        F.col('store_and_fwd_flag').alias('store_and_fwd_flag'),\n","        F.col('PULocationID').cast(IntegerType()).alias('PULocationID'),\n","        F.col('DOLocationID').cast(IntegerType()).alias('DOLocationID'),\n","        F.col('payment_type').cast(IntegerType()).alias('payment_type'),\n","        F.col('fare_amount').cast(DoubleType()).alias('fare_amount'),\n","        F.col('extra').cast(DoubleType()).alias('extra'),\n","        F.col('mta_tax').cast(DoubleType()).alias('mta_tax'),\n","        F.col('tip_amount').cast(DoubleType()).alias('tip_amount'),\n","        F.col('tolls_amount').cast(DoubleType()).alias('tolls_amount'),\n","        F.col('improvement_surcharge').cast(DoubleType()).alias('improvement_surcharge'),\n","        F.col('total_amount').cast(DoubleType()).alias('total_amount'),\n","        F.col('congestion_surcharge').cast(DoubleType()).alias('congestion_surcharge'),\n","        F.col('airport_fee').cast(DoubleType()).alias('airport_fee')\n","    )\n","    \n","    return standardized\n","\n","problematic_years = [2020, 2023]\n","\n","all_years = []\n","\n","for year in range(2019, 2025):\n","    print(f\"\\nProcessing {year}...\")\n","    \n","    try:\n","        year_path = f\"Files/bronze/nyc_taxi/year={year}/\"\n","        \n","        if year in problematic_years:\n","            print(f\"  Using month-by-month processing for {year}\")\n","            month_dfs = []\n","            \n","            for month in range(1, 13):\n","                try:\n","                    month_path = f\"{year_path}month={month:02d}/\"\n","                    df_month = spark.read.parquet(month_path)\n","                    df_month_std = standardize_schema(df_month)\n","                    month_dfs.append(df_month_std)\n","                    print(f\"    Month {month:02d}\")\n","                except Exception as e:\n","                    print(f\"    Month {month:02d}: {str(e)[:80]}\")\n","            \n","            if month_dfs:\n","                df_year_combined = month_dfs[0]\n","                for df in month_dfs[1:]:\n","                    df_year_combined = df_year_combined.union(df)\n","                \n","                print(f\"  Columns before save: {len(df_year_combined.columns)}\")\n","                \n","\n","                temp_table = f\"temp_year_{year}\"\n","                df_year_combined.write \\\n","                    .mode(\"overwrite\") \\\n","                    .format(\"delta\") \\\n","                    .option(\"overwriteSchema\", \"true\") \\\n","                    .saveAsTable(temp_table)\n","                \n","                df_materialized = spark.table(temp_table)\n","                \n","                print(f\"  Columns after load: {len(df_materialized.columns)}\")\n","                \n","                row_count = df_materialized.count()\n","                print(f\"  {year}: {row_count:,} records processed\")\n","                all_years.append(df_materialized)\n","            else:\n","                print(f\"  {year}: No months successfully processed\")\n","        else:\n","            df_year = spark.read.parquet(year_path)\n","            df_standardized = standardize_schema(df_year)\n","            \n","            print(f\"  Columns before save: {len(df_standardized.columns)}\")\n","            \n","            temp_table = f\"temp_year_{year}\"\n","            df_standardized.write \\\n","                .mode(\"overwrite\") \\\n","                .format(\"delta\") \\\n","                .option(\"overwriteSchema\", \"true\") \\\n","                .saveAsTable(temp_table)\n","            \n","            df_materialized = spark.table(temp_table)\n","            \n","            print(f\"  Columns after load: {len(df_materialized.columns)}\")\n","            print(f\"  Column names: {df_materialized.columns[:10]}...\")\n","            \n","            row_count = df_materialized.count()\n","            print(f\"  {year}: {row_count:,} records processed\")\n","            all_years.append(df_materialized)\n","        \n","    except Exception as e:\n","        print(f\"  {year}: Error - {str(e)[:150]}\")\n","        continue\n","\n","print(\"\\nCombining all years...\\n\")\n","\n","if len(all_years) > 0:\n","    df_combined = all_years[0]\n","    for df in all_years[1:]:\n","        df_combined = df_combined.union(df)\n","    \n","    total_records = df_combined.count()\n","    print(f\"Total records: {total_records:,}\")\n","    \n","    print(\"\\nApplying filters and transformations...\")\n","    \n","    df_silver = df_combined.filter(\n","        (F.year('tpep_pickup_datetime').between(2019, 2024)) &\n","        (F.year('tpep_dropoff_datetime').between(2019, 2024)) &\n","        (F.col('tpep_dropoff_datetime') > F.col('tpep_pickup_datetime')) &\n","        \n","        (F.col('fare_amount') >= 0) & (F.col('fare_amount') <= 500) &\n","        (F.col('trip_distance') > 0) & (F.col('trip_distance') <= 100) &\n","        (F.col('passenger_count') >= 1) & (F.col('passenger_count') <= 6)\n","    )\n","    \n","    df_silver = df_silver \\\n","        .withColumn('trip_duration_minutes', \n","                    F.round((F.unix_timestamp('tpep_dropoff_datetime') - \n","                            F.unix_timestamp('tpep_pickup_datetime')) / 60, 2)) \\\n","        .withColumn('pickup_date', F.to_date('tpep_pickup_datetime')) \\\n","        .withColumn('pickup_year', F.year('tpep_pickup_datetime')) \\\n","        .withColumn('pickup_month', F.month('tpep_pickup_datetime')) \\\n","        .withColumn('pickup_day', F.dayofmonth('tpep_pickup_datetime')) \\\n","        .withColumn('pickup_hour', F.hour('tpep_pickup_datetime')) \\\n","        .withColumn('pickup_dayofweek', F.dayofweek('tpep_pickup_datetime')) \\\n","        .withColumn('pickup_dayname', F.date_format('tpep_pickup_datetime', 'EEEE')) \\\n","        .withColumn('is_weekend', \n","                    F.when(F.col('pickup_dayofweek').isin([1, 7]), True).otherwise(False)) \\\n","        .withColumn('speed_mph', \n","                    F.round(F.when(F.col('trip_duration_minutes') > 0, \n","                                  F.col('trip_distance') / (F.col('trip_duration_minutes') / 60))\n","                           .otherwise(0), 2))\n","    \n","    df_silver = df_silver.filter(F.col('speed_mph') <= 100)\n","    \n","    final_count = df_silver.count()\n","    print(f\"After filters: {final_count:,} records\")\n","    print(f\"Records removed: {total_records - final_count:,} ({((total_records - final_count) / total_records * 100):.2f}%)\")\n","    \n","    print(\"\\nSaving to Silver...\")\n","    \n","    spark.sql(\"DROP TABLE IF EXISTS silver_nyc_taxi\")\n","    \n","    df_silver.write \\\n","        .mode(\"overwrite\") \\\n","        .partitionBy(\"pickup_year\", \"pickup_month\") \\\n","        .format(\"delta\") \\\n","        .option(\"overwriteSchema\", \"true\") \\\n","        .saveAsTable(\"silver_nyc_taxi\")\n","    \n","    print(\"YEAR-BY-YEAR SUMMARY\")\n","    \n","    spark.sql(\"\"\"\n","        SELECT \n","            pickup_year,\n","            COUNT(*) as total_trips,\n","            COUNT(DISTINCT pickup_month) as months,\n","            ROUND(SUM(total_amount)/1000000, 2) as revenue_millions,\n","            ROUND(AVG(total_amount), 2) as avg_fare,\n","            ROUND(AVG(trip_distance), 2) as avg_distance_mi,\n","            ROUND(AVG(trip_duration_minutes), 1) as avg_duration_min,\n","            ROUND(AVG(speed_mph), 1) as avg_speed_mph\n","        FROM silver_nyc_taxi\n","        GROUP BY pickup_year\n","        ORDER BY pickup_year\n","    \"\"\").show()\n","    \n","    print(\"VALIDATION CHECKS\")\n","    \n","    print(\"\\nAirport fee coverage by year:\")\n","    spark.sql(\"\"\"\n","        SELECT \n","            pickup_year,\n","            COUNT(*) as total_trips,\n","            SUM(CASE WHEN airport_fee IS NOT NULL AND airport_fee > 0 THEN 1 ELSE 0 END) as trips_with_airport_fee,\n","            ROUND(SUM(CASE WHEN airport_fee IS NOT NULL AND airport_fee > 0 THEN 1 ELSE 0 END) * 100.0 / COUNT(*), 2) as pct_with_fee\n","        FROM silver_nyc_taxi\n","        GROUP BY pickup_year\n","        ORDER BY pickup_year\n","    \"\"\").show()\n","    \n","    print(\"TRANSFORMATION COMPLETE!\")\n","    print(f\"\\nTable: silver_nyc_taxi\")\n","    print(f\"Total records: {final_count:,}\")\n","    print(f\"Years covered: 2019-2024\")\n","    print(f\"Partitioned by: pickup_year, pickup_month\")\n","    \n","    print(\"\\nCleaning up temporary tables...\")\n","    for year in range(2019, 2025):\n","        spark.sql(f\"DROP TABLE IF EXISTS temp_year_{year}\")\n","    print(\"Cleanup complete!\")\n","    \n","    spark.conf.set(\"spark.sql.parquet.enableVectorizedReader\", \"true\")    \n","else:\n","    print(\"\\nNo data was successfully processed!\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":3,"statement_ids":[3],"state":"finished","livy_statement_state":"available","session_id":"14a22c48-e129-414d-959c-ab8343fac341","normalized_state":"finished","queued_time":"2026-01-08T17:01:27.0122488Z","session_start_time":"2026-01-08T17:01:27.0135207Z","execution_start_time":"2026-01-08T17:01:39.1412192Z","execution_finish_time":"2026-01-08T17:11:36.3112829Z","parent_msg_id":"87362245-b540-4077-854d-54005bfeef18"},"text/plain":"StatementMeta(, 14a22c48-e129-414d-959c-ab8343fac341, 3, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["NYC TAXI Bronze to Silver\n\nProcessing 2019...\n  Columns before save: 19\n  Columns after load: 19\n  Column names: ['VendorID', 'tpep_pickup_datetime', 'tpep_dropoff_datetime', 'passenger_count', 'trip_distance', 'RatecodeID', 'store_and_fwd_flag', 'PULocationID', 'DOLocationID', 'payment_type']...\n  2019: 84,598,444 records processed\n\nProcessing 2020...\n  Using month-by-month processing for 2020\n    Month 01\n    Month 02\n    Month 03\n    Month 04\n    Month 05\n    Month 06\n    Month 07\n    Month 08\n    Month 09\n    Month 10\n    Month 11\n    Month 12\n  Columns before save: 19\n  Columns after load: 19\n  2020: 24,649,092 records processed\n\nProcessing 2021...\n  Columns before save: 19\n  Columns after load: 19\n  Column names: ['VendorID', 'tpep_pickup_datetime', 'tpep_dropoff_datetime', 'passenger_count', 'trip_distance', 'RatecodeID', 'store_and_fwd_flag', 'PULocationID', 'DOLocationID', 'payment_type']...\n  2021: 30,904,308 records processed\n\nProcessing 2022...\n  Columns before save: 19\n  Columns after load: 19\n  Column names: ['VendorID', 'tpep_pickup_datetime', 'tpep_dropoff_datetime', 'passenger_count', 'trip_distance', 'RatecodeID', 'store_and_fwd_flag', 'PULocationID', 'DOLocationID', 'payment_type']...\n  2022: 39,656,098 records processed\n\nProcessing 2023...\n  Using month-by-month processing for 2023\n    Month 01\n    Month 02\n    Month 03\n    Month 04\n    Month 05\n    Month 06\n    Month 07\n    Month 08\n    Month 09\n    Month 10\n    Month 11\n    Month 12\n  Columns before save: 19\n  Columns after load: 19\n  2023: 38,310,226 records processed\n\nProcessing 2024...\n  Columns before save: 19\n  Columns after load: 19\n  Column names: ['VendorID', 'tpep_pickup_datetime', 'tpep_dropoff_datetime', 'passenger_count', 'trip_distance', 'RatecodeID', 'store_and_fwd_flag', 'PULocationID', 'DOLocationID', 'payment_type']...\n  2024: 41,169,720 records processed\n\nCombining all years...\n\nTotal records: 259,287,888\n\nApplying filters and transformations...\nAfter filters: 240,890,050 records\nRecords removed: 18,397,838 (7.10%)\n\nSaving to Silver...\nYEAR-BY-YEAR SUMMARY\n+-----------+-----------+------+----------------+--------+---------------+----------------+-------------+\n|pickup_year|total_trips|months|revenue_millions|avg_fare|avg_distance_mi|avg_duration_min|avg_speed_mph|\n+-----------+-----------+------+----------------+--------+---------------+----------------+-------------+\n|       2019|   81699116|    12|         1547.28|   18.94|           3.01|            18.2|         11.3|\n|       2020|   22942488|    12|          406.99|   17.74|           2.77|            15.4|         12.0|\n|       2021|   28233349|    12|          539.47|   19.11|           3.09|            16.4|         12.3|\n|       2022|   36790115|    12|          790.23|   21.48|           3.53|            17.4|         12.0|\n|       2023|   35600827|    12|         1028.71|    28.9|           3.51|            17.6|         11.4|\n|       2024|   35624155|    12|         1033.09|    29.0|           3.44|            17.7|         10.8|\n+-----------+-----------+------+----------------+--------+---------------+----------------+-------------+\n\nVALIDATION CHECKS\n\nAirport fee coverage by year:\n+-----------+-----------+----------------------+------------+\n|pickup_year|total_trips|trips_with_airport_fee|pct_with_fee|\n+-----------+-----------+----------------------+------------+\n|       2019|   81699116|                     0|        0.00|\n|       2020|   22942488|                     0|        0.00|\n|       2021|   28233349|               1409566|        4.99|\n|       2022|   36790115|               2912442|        7.92|\n|       2023|   35600827|               3160573|        8.88|\n|       2024|   35624155|               3147898|        8.84|\n+-----------+-----------+----------------------+------------+\n\nTRANSFORMATION COMPLETE!\n\nTable: silver_nyc_taxi\nTotal records: 240,890,050\nYears covered: 2019-2024\nPartitioned by: pickup_year, pickup_month\n\nCleaning up temporary tables...\nCleanup complete!\n"]}],"execution_count":1,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"},"collapsed":false,"advisor":{"adviceMetadata":"{\"artifactId\":\"a2c11880-5cf9-46d0-a86b-26aecc2a172b\",\"activityId\":\"14a22c48-e129-414d-959c-ab8343fac341\",\"applicationId\":\"application_1767891407161_0001\",\"jobGroupId\":\"3\",\"advices\":{\"info\":2,\"warn\":5}}"}},"id":"b38c7989-bf47-474b-9a26-5b828d25b171"}],"metadata":{"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"name":"synapse_pyspark","display_name":"synapse_pyspark"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"nteract":{"version":"nteract-front-end@1.0.0"},"synapse_widget":{"version":"0.1","state":{}},"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}},"dependencies":{"lakehouse":{"known_lakehouses":[{"id":"c0717884-df49-4052-a6f0-7b820d4d2773"}],"default_lakehouse":"c0717884-df49-4052-a6f0-7b820d4d2773","default_lakehouse_name":"MobilityLakehouse","default_lakehouse_workspace_id":"1c5c8b52-cac8-4458-8854-e182b18bb906"}}},"nbformat":4,"nbformat_minor":5}